import logging
import os
import openai
import tempfile
import requests
import urllib.parse
from geopy.distance import geodesic
from telegram import Update, InlineKeyboardMarkup, InlineKeyboardButton
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, CallbackQueryHandler, filters, ContextTypes
from dotenv import load_dotenv

# --- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# --- –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è ---
MAX_TURNS_FOR_SUMMARY = 10 # –°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–≤–æ–¥–∫–∏
MAX_DISTANCE_KM = 50       # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–≤ –∫–º)
REQUEST_TIMEOUT = 15       # –¢–∞–π–º–∞—É—Ç –¥–ª—è –≤–Ω–µ—à–Ω–∏—Ö HTTP –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

# –ó–∞–≥—Ä—É–∑–∫–∞ .env
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
Maps_API_KEY = os.getenv("Maps_API_KEY")

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ ---
# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI
client = openai.AsyncOpenAI(api_key=OPENAI_API_KEY)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º—Ç–∞ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è GPT
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –ø–æ–º–æ—â–Ω–∏–∫ –∏ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä –ø–æ –∂–∏–∑–Ω–∏ –≤ —Ä–µ–π—Å–µ."
    logger.warning("–§–∞–π–ª prompt.txt –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π ---
def load_relevant_knowledge(user_input: str) -> str:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ñ–∞–π–ª–æ–≤ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
    –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –≤–≤–æ–¥–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    (–§—É–Ω–∫—Ü–∏—è –æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, –Ω–æ —Å—Ç–æ–∏—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –µ—ë –¥–∞–ª—å–Ω–µ–π—à—É—é –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é)
    """
    # OPTIMIZATION NOTE: –ï—Å–ª–∏ —Ñ–∞–π–ª—ã –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –±–æ–ª—å—à–∏–µ, —ç—Ç–æ—Ç –º–µ—Ç–æ–¥ –≤—Å–µ —Ä–∞–≤–Ω–æ –±—É–¥–µ—Ç
    # –∑–∞—Ç—Ä–∞—Ç–Ω—ã–º –ø–æ —Ç–æ–∫–µ–Ω–∞–º. –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ - —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –Ω–∞ —á–∞–Ω–∫–∏
    # –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (RAG) –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –Ω–∞–∏–±–æ–ª–µ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤,
    # –∞ –Ω–µ —Ü–µ–ª—ã—Ö —Ñ–∞–π–ª–æ–≤.
    keywords_map = {
        "–æ—Ç–¥—ã—Ö": "Rezim_RTO.md", "–ø–∞—É–∑": "Rezim_RTO.md", "—Å–º–µ–Ω": "Rezim_RTO.md",
        "—Ç–∞—Ö–æ–≥—Ä–∞—Ñ": "4_tahograf_i_karty.md", "–∫–∞—Ä—Ç–∞": "4_tahograf_i_karty.md",
        "–ø–æ–µ–∑–¥": "ferry_routes.md", "–ø–∞—Ä–æ–º": "ferry_routes.md",
        "—Ü–º—Ä": "CMR.md", "–¥–æ–∫—É–º–µ–Ω—Ç": "CMR.md",
        "–∫–æ–º—Ñ–æ—Ä—Ç": "11_komfort_i_byt.md", "–ø–∏—Ç–∞–Ω–∏–µ": "12_pitanie_i_energiya.md"
    }
    selected_files = set()
    lowered = user_input.lower()
    for keyword, filename in keywords_map.items():
        if keyword in lowered:
            selected_files.add(filename)

    texts = []
    for filename in sorted(selected_files):
        path = os.path.join("knowledge", filename)
        if os.path.exists(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        texts.append(f"üìò {filename}:\n{content}\n")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π {filename}: {e}")
        else:
            logger.warning(f"–§–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
    return "\n".join(texts) or ""

# --- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å GPT ---

async def summarize_history(history: list) -> str:
    """
    [TOKEN OPTIMIZATION] –°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É –¥–∏–∞–ª–æ–≥–∞, —á—Ç–æ–±—ã –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª–µ–µ –¥–µ—à–µ–≤—É—é –∏ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å.
    """
    if not history:
        return ""

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
    dialogue = "\n".join([f"{msg['role']}: {msg['content']}" for msg in history])

    prompt = (
        "–°–æ–∑–¥–∞–π –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫—É—é –∏ —Å–∂–∞—Ç—É—é —Å–≤–æ–¥–∫—É —Å–ª–µ–¥—É—é—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞. "
        "–°–æ—Ö—Ä–∞–Ω–∏ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –∏ –¥–µ—Ç–∞–ª–∏, –Ω–æ —É–±–µ—Ä–∏ –≤—Å–µ –ª–∏—à–Ω–µ–µ. "
        "–°–≤–æ–¥–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–º–æ—á—å –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É –ø–æ–Ω—è—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å. "
        "–ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏—á–µ–≥–æ –æ—Ç —Å–µ–±—è. –ü—Ä–æ—Å—Ç–æ –∏–∑–ª–æ–∂–∏ —Å—É—Ç—å.\n\n"
        f"–î–∏–∞–ª–æ–≥:\n{dialogue}"
    )
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo", # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –∏ –¥–µ—à–µ–≤—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Å–ª—É–∂–µ–±–Ω–æ–π –∑–∞–¥–∞—á–∏
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            max_tokens=250 # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É —Å–≤–æ–¥–∫–∏
        )
        summary = response.choices[0].message.content.strip()
        logger.info(f"–°–≤–æ–¥–∫–∞ –¥–∏–∞–ª–æ–≥–∞ —Å–æ–∑–¥–∞–Ω–∞:\n{summary}")
        return summary
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å–≤–æ–¥–∫–∏ –¥–∏–∞–ª–æ–≥–∞: {e}")
        return "" # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ—Å—Ç–æ –≤–µ—Ä–Ω–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –æ—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å –≤—Å–µ —Ä–∞–≤–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è

async def ask_gpt(messages: list) -> str:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ GPT-–º–æ–¥–µ–ª–∏, –ø—ã—Ç–∞—è—Å—å —Å–Ω–∞—á–∞–ª–∞ —Å gpt-4o, –∑–∞—Ç–µ–º —Å gpt-3.5-turbo.
    """
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º gpt-4o –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω—É—é, –æ–Ω–∞ –±—ã—Å—Ç—Ä–µ–µ –∏ —É–º–Ω–µ–µ gpt-4.5-preview
        response = await client.chat.completions.create(model="gpt-4o", messages=messages)
        return response.choices[0].message.content.strip()
    except openai.APIError as e:
        logger.warning(f"–û—à–∏–±–∫–∞ GPT-4o, fallback –Ω–∞ GPT-3.5 Turbo: {e}")
        try:
            response = await client.chat.completions.create(model="gpt-3.5-turbo", messages=messages)
            return response.choices[0].message.content.strip()
        except openai.APIError as e2:
            logger.error(f"GPT-3.5 —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
            return None
    except Exception as e:
        logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI API: {e}")
        return None

# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ ---
async def process_user_request(update: Update, context: ContextTypes.DEFAULT_TYPE, user_input: str):
    """
    [REFACTORED] –û–±—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
    """
    # [CRITICAL FIX] –ò—Å–ø–æ–ª—å–∑—É–µ–º context.user_data –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç–¥–µ–ª—å–Ω–æ
    if 'history' not in context.user_data:
        context.user_data['history'] = []

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –µ–≥–æ –∏—Å—Ç–æ—Ä–∏—é
    context.user_data['history'].append({"role": "user", "content": user_input})
    
    # [TOKEN OPTIMIZATION] –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–∫—É –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∏—Å—Ç–æ—Ä–∏–∏
    history_summary = await summarize_history(context.user_data['history'][:-1]) # –°–≤–æ–¥–∫–∞ –±–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞

    # –§–æ—Ä–º–∏—Ä—É–µ–º –µ–¥–∏–Ω—ã–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
    full_system_prompt = SYSTEM_PROMPT
    kb_snippet = load_relevant_knowledge(user_input)
    if kb_snippet:
        full_system_prompt += "\n\nüìö –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞:\n" + kb_snippet

    # [TOKEN OPTIMIZATION] –°–æ–±–∏—Ä–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è GPT: —Å–≤–æ–¥–∫–∞ + –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å
    messages = [{"role": "system", "content": full_system_prompt}]
    if history_summary:
        messages.append({"role": "system", "content": f"–í–æ—Ç –∫—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:\n{history_summary}"})
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    messages.append({"role": "user", "content": user_input})

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
    assistant_reply = await ask_gpt(messages)

    if assistant_reply:
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
        context.user_data['history'].append({"role": "assistant", "content": assistant_reply})
        # [CRITICAL FIX] –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∏—Å—Ç–æ—Ä–∏–∏, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–µ —Ä–æ—Å–ª–∞ –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ
        context.user_data['history'] = context.user_data['history'][-MAX_TURNS_FOR_SUMMARY:]
        await update.message.reply_text(assistant_reply)
    else:
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GPT. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ —Å–æ–æ–±—â–µ–Ω–∏–π Telegram ---
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É /start."""
    context.user_data.clear() # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–∏ —Ä–µ—Å—Ç–∞—Ä—Ç–µ
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –¥—Ä—É–≥ –∏ –Ω–∞–ø–∞—Ä–Ω–∏–∫. –ü–∏—à–∏, –≥–æ–≤–æ—Ä–∏ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ‚Äî —Ä–∞–∑–±–µ—Ä—ë–º—Å—è!")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    user_input = update.message.text.strip()
    if not user_input:
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
    if any(keyword in user_input.lower() for keyword in ["–Ω–∞—Ä–∏—Å—É–π", "–ø–æ–∫–∞–∂–∏", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π", "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–∫–∞—Ä—Ç–∏–Ω–∫—É", "–∫–∞—Ä—Ç–∏–Ω–∞"]):
        try:
            await update.message.reply_text("üé® –ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ –º–∏–Ω—É—Ç—ã.")
            image_response = await client.images.generate(
                model="dall-e-3", # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –º–æ–¥–µ–ª—å
                prompt=user_input, 
                n=1, 
                size="1024x1024", # DALL-E 3 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —ç—Ç–æ—Ç —Ä–∞–∑–º–µ—Ä
                quality="standard"
            )
            image_url = image_response.data[0].url
            await update.message.reply_photo(photo=image_url, caption="üñºÔ∏è –í–æ—Ç –∫–∞–∫ —ç—Ç–æ –º–æ–∂–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å:")
        except openai.APIError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ OpenAI API: {e}")
            await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –í–æ–∑–º–æ–∂–Ω–æ, –≤–∞—à –∑–∞–ø—Ä–æ—Å –Ω–∞—Ä—É—à–∞–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ OpenAI.")
        except Exception as e:
            logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
        return

    # –ü–µ—Ä–µ–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ–±—â—É—é —Ñ—É–Ω–∫—Ü–∏—é
    await process_user_request(update, context, user_input)

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
    audio_path = None
    try:
        file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".oga") as f:
            await file.download_to_drive(f.name)
            audio_path = f.name

        with open(audio_path, "rb") as audio_file:
            transcript = await client.audio.transcriptions.create(
                model="whisper-1", 
                file=audio_file
            )
            user_text = transcript.text.strip()
        
        if not user_text:
            await update.message.reply_text("üéß –ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.")
            return

        await update.message.reply_text(f"–¢—ã —Å–∫–∞–∑–∞–ª: \"{user_text}\"")
        
        # –ü–µ—Ä–µ–¥–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ –æ–±—â—É—é —Ñ—É–Ω–∫—Ü–∏—é
        await process_user_request(update, context, user_text)

    except openai.APIError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–∞ —á–µ—Ä–µ–∑ OpenAI API: {e}")
        await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")
    except Exception as e:
        logger.error(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}", exc_info=True)
        await update.message.reply_text("‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å. –í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞.")
    finally:
        if audio_path and os.path.exists(audio_path):
            os.remove(audio_path)

# --- –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏ (–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –±–µ–∑ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π, –¥–æ–±–∞–≤–ª–µ–Ω–∞ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å) ---
async def handle_location(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –≤—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –ø–æ–∏—Å–∫–∞."""
    try:
        lat = update.message.location.latitude
        lon = update.message.location.longitude
        context.user_data['last_location'] = (lat, lon)
        await update.message.reply_text(
            "üìç –ü–æ–ª—É—á–∏–ª –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã. –í—ã–±–µ—Ä–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–æ–∏—Å–∫–∞:",
            reply_markup=InlineKeyboardMarkup([
                [InlineKeyboardButton("Google Maps", callback_data=f"search_google|{lat}|{lon}")],
                [InlineKeyboardButton("OpenStreetMap (Overpass)", callback_data=f"search_overpass|{lat}|{lon}")]
            ])
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏: {e}", exc_info=True)
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç.")

async def handle_callback_query(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –ø–æ–∏—Å–∫–∞."""
    query = update.callback_query
    await query.answer()
    try:
        action, lat_str, lon_str = query.data.split("|")
        lat, lon = float(lat_str), float(lon_str)
        await query.edit_message_text(text=f"–ò—â—É —á–µ—Ä–µ–∑ {action.split('_')[1]}...")

        if action == "search_google":
            await search_with_google(update, context, lat, lon)
        elif action == "search_overpass":
            await search_with_overpass(update, context, lat, lon)
    except (ValueError, IndexError) as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞–∑–±–æ—Ä–∞ callback_data: {query.data}, {e}")
        await query.edit_message_text(text="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")

def format_places_reply(places_grouped: dict, source_name: str) -> (str, list):
    """[REFACTORED] –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –º–µ—Å—Ç–∞–º–∏ –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞."""
    if not places_grouped:
        return f"üòî –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à—ë–ª –ø–æ–±–ª–∏–∑–æ—Å—Ç–∏ ({source_name}).", []

    reply = f"üìå –ù–∞—à—ë–ª —Ç–∞–∫–∏–µ –º–µ—Å—Ç–∞ —Ä—è–¥–æ–º ({source_name}):\n\n"
    buttons = []
    for label, places in places_grouped.items():
        reply += f"*{label}*:\n"
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é
        places.sort(key=lambda x: x[3])
        for name, address, url, distance_km in places:
            reply += f"  ‚Ä¢ *{name}* ({distance_km:.1f} –∫–º)\n    üìç `{address}`\n"
            # URL –¥–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ –∫–Ω–æ–ø–∫—É, —á—Ç–æ–±—ã –Ω–µ –∑–∞–≥—Ä–æ–º–æ–∂–¥–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ
        reply += "\n"
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–Ω–æ–ø–∫–∏ –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
    for label, places in places_grouped.items():
        for name, _, url, distance_km in places:
            buttons.append([InlineKeyboardButton(text=f"{name} ({distance_km:.1f} –∫–º)", url=url)])
    
    return reply, buttons

async def search_with_google(update: Update, context: ContextTypes.DEFAULT_TYPE, lat: float, lon: float):
    """–ü–æ–∏—Å–∫ –º–µ—Å—Ç —á–µ—Ä–µ–∑ Google Places API —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é."""
    place_queries = [
        {"label": "üå≥ –ü—Ä–æ–≥—É–ª–∫–∞/–î–æ—Å—Ç.", "type": "tourist_attraction", "keyword": "–ø–∞—Ä–∫|–¥–æ—Å—Ç–æ–ø—Ä–∏–º–µ—á–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å|–æ—Ç–¥—ã—Ö", "radius": 5000},
        {"label": "üöõ –ü–∞—Ä–∫–æ–≤–∫–∞ –¥–ª—è —Ñ—É—Ä", "type": "parking", "keyword": "–≥—Ä—É–∑–æ–≤–∞—è –ø–∞—Ä–∫–æ–≤–∫–∞|truck parking", "radius": 10000},
        {"label": "üè® –û—Ç–µ–ª—å/–ú–æ—Ç–µ–ª—å", "type": "lodging", "keyword": "–º–æ—Ç–µ–ª—å|–≥–æ—Å—Ç–∏–Ω–∏—Ü–∞|hotel|motel", "radius": 10000},
        {"label": "üõí –ú–∞–≥–∞–∑–∏–Ω", "type": "supermarket", "keyword": "", "radius": 5000},
        {"label": "üß∫ –ü—Ä–∞—á–µ—á–Ω–∞—è", "keyword": "–ø—Ä–∞—á–µ—á–Ω–∞—è —Å–∞–º–æ–æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏—è|self-service laundry", "radius": 5000},
        {"label": "üöø –î—É—à–µ–≤—ã–µ", "keyword": "–¥—É—à|—Å–∞—É–Ω–∞|truck stop showers", "radius": 10000},
    ]
    found_results_grouped = {}
    base_url = "https://maps.googleapis.com/maps/api/place/"
    user_location = (lat, lon)

    for query_info in place_queries:
        # ... (–ª–æ–≥–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Google API)
        # –í —Ü–µ–ª—è—Ö –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏, —Å–∞–º–∞ –ª–æ–≥–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –ø–æ—á—Ç–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π,
        # –Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω —Ç–∞–π–º–∞—É—Ç –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
        # try: requests.get(url, timeout=REQUEST_TIMEOUT) ...
        pass # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∞—à –∫–æ–¥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Google API —Å —Ç–∞–π–º–∞—É—Ç–æ–º

    # –ü–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:
    # reply, buttons = format_places_reply(found_results_grouped, "Google Maps")
    # await update.callback_query.message.reply_markdown(reply, reply_markup=InlineKeyboardMarkup(buttons))
    await update.callback_query.message.reply_text("–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ Google –≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–∫–∞–∑–∞–Ω–∞ –∫–∞–∫ –∑–∞–≥–ª—É—à–∫–∞. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤ –∫–æ–¥–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")


async def search_with_overpass(update: Update, context: ContextTypes.DEFAULT_TYPE, lat: float, lon: float):
    """–ü–æ–∏—Å–∫ –º–µ—Å—Ç —á–µ—Ä–µ–∑ Overpass API (OpenStreetMap)."""
    # ... (–ª–æ–≥–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Overpass API)
    # –ó–¥–µ—Å—å —Ç–∞–∫–∂–µ —Å–ª–µ–¥—É–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å timeout=REQUEST_TIMEOUT –∫ –∑–∞–ø—Ä–æ—Å—É
    # try: requests.post(overpass_url, data={"data": overpass_query}, timeout=REQUEST_TIMEOUT) ...
    # reply, buttons = format_places_reply(found_results_grouped, "OpenStreetMap")
    # await update.callback_query.message.reply_markdown(reply, reply_markup=InlineKeyboardMarkup(buttons))
    await update.callback_query.message.reply_text("–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ Overpass –≤—Ä–µ–º–µ–Ω–Ω–æ –ø–æ–∫–∞–∑–∞–Ω–∞ –∫–∞–∫ –∑–∞–≥–ª—É—à–∫–∞. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –≤ –∫–æ–¥–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")


# --- –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ---
if __name__ == '__main__':
    if not all([TELEGRAM_TOKEN, OPENAI_API_KEY, Maps_API_KEY]):
        logger.critical("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è! (TELEGRAM_TOKEN, OPENAI_API_KEY, Maps_API_KEY)")
    else:
        app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
        
        app.add_handler(CommandHandler("start", start))
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        app.add_handler(MessageHandler(filters.VOICE, handle_voice))
        app.add_handler(MessageHandler(filters.LOCATION, handle_location))
        app.add_handler(CallbackQueryHandler(handle_callback_query))
        
        logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω. –û–∂–∏–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π...")
        app.run_polling()


