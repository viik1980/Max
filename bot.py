import logging
import os
import openai
import tempfile
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
from overpass_utils import query_overpass, parse_places

# –ü—Ä–æ—Å—Ç–∞—è –ø–∞–º—è—Ç—å –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
context_history = []
MAX_TURNS = 6

# –ó–∞–≥—Ä—É–∑–∫–∞ .env
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º—Ç–∞
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –ø–æ–º–æ—â–Ω–∏–∫ –∏ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä –ø–æ –∂–∏–∑–Ω–∏ –≤ —Ä–µ–π—Å–µ."

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
def load_relevant_knowledge(user_input: str) -> str:
    keywords_map = {
        "–æ—Ç–¥—ã—Ö": "Rezim_RTO.md",
        "–ø–∞—É–∑": "Rezim_RTO.md",
        "—Å–º–µ–Ω": "Rezim_RTO.md",
        "—Ç–∞—Ö–æ–≥—Ä–∞—Ñ": "4_tahograf_i_karty.md",
        "–∫–∞—Ä—Ç–∞": "4_tahograf_i_karty.md",
        "–ø–æ–µ–∑–¥": "ferry_routes.md",
        "–ø–∞—Ä–æ–º": "ferry_routes.md",
        "—Ü–º—Ä": "CMR.md",
        "–¥–æ–∫—É–º–µ–Ω—Ç": "CMR.md",
        "–∫–æ–º—Ñ–æ—Ä—Ç": "11_komfort_i_byt.md",
        "–ø–∏—Ç–∞–Ω–∏–µ": "12_pitanie_i_energiya.md"
    }

    selected_files = set()
    lowered = user_input.lower()
    for keyword, filename in keywords_map.items():
        if keyword in lowered:
            selected_files.add(filename)

    texts = []
    for filename in sorted(selected_files):
        path = os.path.join("knowledge", filename)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    texts.append(f"üìò {filename}:\n{content}\n")

    return "\n".join(texts) or ""

# GPT-–∑–∞–ø—Ä–æ—Å
async def ask_gpt(messages):
    try:
        return openai.ChatCompletion.create(model="gpt-4.5-preview", messages=messages)
    except Exception as e:
        logging.warning(f"GPT-4.5-preview –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, fallback: {e}")
        try:
            return openai.ChatCompletion.create(model="gpt-3.5-turbo-1106", messages=messages)
        except Exception as e2:
            logging.error(f"GPT-3.5 —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
            return None

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –¥—Ä—É–≥ –∏ –Ω–∞–ø–∞—Ä–Ω–∏–∫. –ü–∏—à–∏, –≥–æ–≤–æ—Ä–∏ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è–π –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã ‚Äî —Ä–∞–∑–±–µ—Ä—ë–º—Å—è!")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    if not user_input:
        await update.message.reply_text("–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    lowered = user_input.lower()

    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    if any(keyword in lowered for keyword in ["–Ω–∞—Ä–∏—Å—É–π", "–ø–æ–∫–∞–∂–∏", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π", "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–∫–∞—Ä—Ç–∏–Ω–∫—É", "–∫–∞—Ä—Ç–∏–Ω–∞"]):
        try:
            image_response = openai.Image.create(prompt=user_input, n=1, size="512x512")
            image_url = image_response['data'][0]['url']
            await update.message.reply_photo(photo=image_url, caption="üñºÔ∏è –í–æ—Ç –∫–∞–∫ —ç—Ç–æ –º–æ–∂–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å:")
            return
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
            return

    # –ö–æ–Ω—Ç–µ–∫—Å—Ç
    context_history.append({"role": "user", "content": user_input})
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    kb_snippet = load_relevant_knowledge(user_input)
    if kb_snippet:
        messages.append({"role": "system", "content": "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + kb_snippet})
    messages += context_history[-MAX_TURNS:]

    response = await ask_gpt(messages)
    if response:
        assistant_reply = response.choices[0].message.content.strip()
        context_history.append({"role": "assistant", "content": assistant_reply})
        await update.message.reply_text(assistant_reply)
    else:
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GPT. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".oga") as f:
            await file.download_to_drive(f.name)
            audio_path = f.name

        with open(audio_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe("whisper-1", audio_file)
            user_text = transcript.get("text", "")

        if not user_text:
            await update.message.reply_text("üéß –ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π —Å–Ω–æ–≤–∞.")
            return

        await update.message.reply_text(f"–¢—ã —Å–∫–∞–∑–∞–ª: {user_text}")

        context_history.append({"role": "user", "content": user_text})
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        kb_snippet = load_relevant_knowledge(user_text)
        if kb_snippet:
            messages.append({"role": "system", "content": "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + kb_snippet})
        messages += context_history[-MAX_TURNS:]

        response = await ask_gpt(messages)
        if response:
            assistant_reply = response.choices[0].message.content.strip()
            context_history.append({"role": "assistant", "content": assistant_reply})
            await update.message.reply_text(assistant_reply)
        else:
            await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GPT. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

    except Exception as e:
        logging.error(f"[ERROR] –ì–æ–ª–æ—Å–æ–≤–∞—è –æ—à–∏–±–∫–∞: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ù–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å. –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ —Å —Ñ–æ—Ä–º–∞—Ç–æ–º.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–µ–æ–ª–æ–∫–∞—Ü–∏–∏
async def handle_location(update: Update, context: ContextTypes.DEFAULT_TYPE):
    lat = update.message.location.latitude
    lon = update.message.location.longitude
    await update.message.reply_text("üìç –ü–æ–ª—É—á–∏–ª –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã. –ò—â—É —Ä—è–¥–æ–º –º–∞–≥–∞–∑–∏–Ω—ã, –ø–∞—Ä–∫–æ–≤–∫–∏ –∏ –∞–ø—Ç–µ–∫–∏...")

    data = await query_overpass(lat, lon)
    if data:
        places = parse_places(data)
        if places:
            await update.message.reply_text("\n\n".join(places))
        else:
            await update.message.reply_text("‚ùó –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à—ë–ª –ø–æ–±–ª–∏–∑–æ—Å—Ç–∏.")
    else:
        await update.message.reply_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç Overpass API.")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.add_handler(MessageHandler(filters.LOCATION, handle_location))
    app.run_polling()
