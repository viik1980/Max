import logging
import os
import openai
import tempfile
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise ValueError("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY.")

openai.api_key = OPENAI_API_KEY

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç (–∏–∑ —Ñ–∞–π–ª–∞ prompt.txt –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –û–ø—ã—Ç–Ω—ã–π –¥–∏—Å–ø–µ—Ç—á–µ—Ä –∏ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä –ø–æ –∂–∏–∑–Ω–∏ –≤ —Ä–µ–π—Å–µ. –û—Ç–≤–µ—á–∞–π —Å –∑–∞–±–æ—Ç–æ–π, –ø–æ-–¥—Ä—É–∂–µ—Å–∫–∏, —Å —é–º–æ—Ä–æ–º, –Ω–æ –ø–æ –¥–µ–ª—É. –ü–æ–º–æ–≥–∞–µ—à—å –≤–æ–¥–∏—Ç–µ–ª—è–º –≤ –ø—É—Ç–∏, —Å —Ä–µ–∂–∏–º–∞–º–∏ —Ç—Ä—É–¥–∞ –∏ –æ—Ç–¥—ã—Ö–∞, –ø–∞—Ä–æ–º–∞–º–∏, –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º."

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ –ø–∞–ø–∫–∏ knowledge
def load_all_knowledge():
    knowledge_dir = "knowledge"
    texts = []
    if not os.path.exists(knowledge_dir):
        logging.warning(f"–ü–∞–ø–∫–∞ —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π '{knowledge_dir}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return ""
    files = os.listdir(knowledge_dir)
    logging.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –≤ knowledge: {files}")
    for filename in sorted(files):
        path = os.path.join(knowledge_dir, filename)
        if os.path.isfile(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        texts.append(f"\nüìò {filename}\n{content}\n")
                    else:
                        logging.warning(f"–§–∞–π–ª {filename} –ø—É—Å—Ç–æ–π.")
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π {filename}: {e}")
        else:
            logging.info(f"{filename} –Ω–µ —Ñ–∞–π–ª, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
    return "\n".join(texts)

KNOWLEDGE_BASE = load_all_knowledge()
logging.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π, —Å–∏–º–≤–æ–ª–æ–≤: {len(KNOWLEDGE_BASE)}")

# –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–Ω–∞—á–∞–ª–∞ gpt-4o, –µ—Å–ª–∏ –æ—à–∏–±–∫–∞ ‚Äî –æ—Ç–∫–∞—Ç–∏—Ç—å—Å—è –Ω–∞ 3.5-turbo
async def ask_gpt(messages):
    try:
        return openai.ChatCompletion.create(
            model="gpt-4o",
            messages=messages
        )
    except Exception as e:
        logging.warning(f"GPT-4o –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–±—É–µ–º gpt-3.5-turbo-1106. –û—à–∏–±–∫–∞: {e}")
        try:
            return openai.ChatCompletion.create(
                model="gpt-3.5-turbo-1106",
                messages=messages
            )
        except Exception as e2:
            logging.error(f"GPT-3.5 —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
            return None

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logging.info("[LOG] /start –ø–æ–ª—É—á–µ–Ω–∞")
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –¥—Ä—É–≥ –∏ –Ω–∞–ø–∞—Ä–Ω–∏–∫ –≤ —Ä–µ–π—Å–µ. –ì–¥–µ –µ—Ö–∞—Ç—å, –≥–¥–µ —Å–ø–∞—Ç—å, –∫–æ–≥–¥–∞ –∂—Ä–∞—Ç—å –∏ –Ω–µ —Å–ª–µ—Ç–µ—Ç—å —Å –∫–∞—Ç—É—à–µ–∫ ‚Äî —è —Ä—è–¥–æ–º. –ü–∏—à–∏!")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    logging.info(f"[LOG] –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_input}")

    if not user_input:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏, —á–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
    ]
    if KNOWLEDGE_BASE:
        messages.append({"role": "system", "content": "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + KNOWLEDGE_BASE})
    messages.append({"role": "user", "content": user_input})

    response = await ask_gpt(messages)
    if response:
        reply = response.choices[0].message.content.strip()
        await update.message.reply_text(reply)
    else:
        await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ –º–æ–∂–µ—Ç —Å–≤—è–∑–∞—Ç—å—Å—è —Å GPT. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".oga") as f:
            await file.download_to_drive(f.name)
            audio_path = f.name

        with open(audio_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe("whisper-1", audio_file)
            user_text = transcript.get("text", "")

        if not user_text:
            await update.message.reply_text("–ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π —Å–∫–∞–∑–∞—Ç—å —Å–Ω–æ–≤–∞.")
            return

        await update.message.reply_text(f"–¢—ã —Å–∫–∞–∑–∞–ª: {user_text}")

        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
        ]
        if KNOWLEDGE_BASE:
            messages.append({"role": "system", "content": "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + KNOWLEDGE_BASE})
        messages.append({"role": "user", "content": user_text})

        response = await ask_gpt(messages)
        if response:
            reply = response.choices[0].message.content.strip()
            await update.message.reply_text(reply)
        else:
            await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ –º–æ–∂–µ—Ç —Å–≤—è–∑–∞—Ç—å—Å—è —Å GPT. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å. –ü—Ä–æ–≤–µ—Ä—å —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.run_polling()
