import logging
import os
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
from datetime import datetime
from logic.route_calc import calculate_eta


# –ü—Ä–æ—Å—Ç–µ–π—à–∞—è –ø–∞–º—è—Ç—å –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
context_history = []
MAX_TURNS = 6

# –ó–∞–≥—Ä—É–∑–∫–∞ .env
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º—Ç–∞
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –ø–æ–º–æ—â–Ω–∏–∫ –∏ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä –ø–æ –∂–∏–∑–Ω–∏ –≤ —Ä–µ–π—Å–µ."

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ -> –∑–Ω–∞–Ω–∏—è
def load_relevant_knowledge(user_input: str) -> str:
    keywords_map = {
        "–æ—Ç–¥—ã—Ö": "Rezim_RTO.md",
        "–ø–∞—É–∑": "Rezim_RTO.md",
        "—Å–º–µ–Ω": "Rezim_RTO.md",
        "—Ç–∞—Ö–æ–≥—Ä–∞—Ñ": "4_tahograf_i_karty.md",
        "–∫–∞—Ä—Ç–∞": "4_tahograf_i_karty.md",
        "–ø–æ–µ–∑–¥": "ferry_routes.md",
        "–ø–∞—Ä–æ–º": "ferry_routes.md",
        "—Ü–º—Ä": "CMR.md",
        "–¥–æ–∫—É–º–µ–Ω—Ç": "CMR.md",
        "–∫–æ–º—Ñ–æ—Ä—Ç": "11_komfort_i_byt.md",
        "–ø–∏—Ç–∞–Ω–∏–µ": "12_pitanie_i_energiya.md"
    }

    selected_files = set()
    lowered = user_input.lower()
    for keyword, filename in keywords_map.items():
        if keyword in lowered:
            selected_files.add(filename)

    texts = []
    for filename in sorted(selected_files):
        path = os.path.join("knowledge", filename)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    texts.append(f"üìò {filename}:\n{content}\n")

    return "\n".join(texts) or ""

# GPT-–∑–∞–ø—Ä–æ—Å
async def ask_gpt(messages):
    try:
        return openai.ChatCompletion.create(model="gpt-4o", messages=messages)
    except Exception as e:
        logging.warning(f"GPT-4o –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, fallback: {e}")
        try:
            return openai.ChatCompletion.create(model="gpt-3.5-turbo-1106", messages=messages)
        except Exception as e2:
            logging.error(f"GPT-3.5 —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
            return None

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –¥—Ä—É–≥ –∏ –Ω–∞–ø–∞—Ä–Ω–∏–∫. –ü–∏—à–∏ ‚Äî –ø–æ–º–æ–≥—É.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    if not user_input:
        await update.message.reply_text("–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    lowered = user_input.lower()

    # –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É
    if any(keyword in lowered for keyword in ["–Ω–∞—Ä–∏—Å—É–π", "–ø–æ–∫–∞–∂–∏", "—Å–≥–µ–Ω–µ—Ä–∏—Ä—É–π", "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–∫–∞—Ä—Ç–∏–Ω–∫—É", "–∫–∞–∫ –≤—ã–≥–ª—è–¥–∏—Ç", "–∫–∞—Ä—Ç–∏–Ω–∞"]):
        try:
            image_response = openai.Image.create(
                prompt=user_input,
                n=1,
                size="512x512"
            )
            image_url = image_response['data'][0]['url']
            await update.message.reply_photo(photo=image_url, caption="üñºÔ∏è –í–æ—Ç –∫–∞–∫ —ç—Ç–æ –º–æ–∂–µ—Ç –≤—ã–≥–ª—è–¥–µ—Ç—å:")
            return
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            await update.message.reply_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
            return

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    context_history.append({"role": "user", "content": user_input})

    # –ì–æ—Ç–æ–≤–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è GPT
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    kb_snippet = load_relevant_knowledge(user_input)
    if kb_snippet:
        messages.append({"role": "system", "content": "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + kb_snippet})
    messages += context_history[-MAX_TURNS:]

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç
    response = await ask_gpt(messages)

    if response:
        assistant_reply = response.choices[0].message.content.strip()
        context_history.append({"role": "assistant", "content": assistant_reply})
        await update.message.reply_text(assistant_reply)
    else:
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GPT. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –ó–∞–ø—É—Å–∫
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()
