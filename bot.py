import logging
import os
import openai
import tempfile
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞ –∏–∑ –ø–∞–ø–∫–∏ knowledge
def load_knowledge(filename):
    try:
        with open(f"knowledge/{filename}", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ knowledge
def load_all_knowledge():
    knowledge_base = ""
    knowledge_dir = "knowledge"
    if os.path.exists(knowledge_dir):
        for filename in os.listdir(knowledge_dir):
            if filename.endswith(".txt"):
                knowledge_base += f"\n--- {filename} ---\n"
                knowledge_base += load_knowledge(filename)
                knowledge_base += "\n"
    return knowledge_base.strip()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise ValueError("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY.")

openai.api_key = OPENAI_API_KEY

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç (–∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –û–ø—ã—Ç–Ω—ã–π –¥–∏—Å–ø–µ—Ç—á–µ—Ä. –û—Ç–≤–µ—á–∞–π –ø–æ-–¥—Ä—É–∂–µ—Å–∫–∏, —Å –∑–∞–±–æ—Ç–æ–π, –ø–æ –¥–µ–ª—É –∏ —Å —É–º–µ—Å—Ç–Ω—ã–º —é–º–æ—Ä–æ–º."

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
KNOWLEDGE_BASE = load_all_knowledge()

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    print("[LOG] /start –ø–æ–ª—É—á–µ–Ω–∞")
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä –∏ –¥—Ä—É–≥. –ü–∏—à–∏ –∏–ª–∏ –≥–æ–≤–æ—Ä–∏ ‚Äî —Ä–∞–∑–±–µ—Ä—ë–º—Å—è!")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    print(f"[LOG] –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_input}")

    if not user_input:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏, —á–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    try:
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": "üìö –í–æ—Ç –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + KNOWLEDGE_BASE},
            {"role": "user", "content": user_input},
        ]

        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=messages
        )

        print(f"[LOG] GPT —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {response}")
        reply = response.choices[0].message.content if response.choices else "GPT –Ω–µ –¥–∞–ª –æ—Ç–≤–µ—Ç–∞."
        await update.message.reply_text(reply)

    except Exception as e:
        print(f"[ERROR] GPT –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ –º–æ–∂–µ—Ç —Å–≤—è–∑–∞—Ç—å—Å—è —Å GPT. –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".oga") as f:
            await file.download_to_drive(f.name)
            audio_path = f.name

        with open(audio_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe("whisper-1", audio_file)
            user_text = transcript.get("text", "")

        if not user_text:
            await update.message.reply_text("–ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π —Å–∫–∞–∑–∞—Ç—å —Å–Ω–æ–≤–∞.")
            return

        await update.message.reply_text(f"–¢—ã —Å–∫–∞–∑–∞–ª: {user_text}")

        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": "üìö –í–æ—Ç –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + KNOWLEDGE_BASE},
            {"role": "user", "content": user_text},
        ]

        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=messages
        )

        print(f"[LOG] GPT –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç: {response}")
        reply = response.choices[0].message.content if response.choices else "GPT –Ω–µ –¥–∞–ª –æ—Ç–≤–µ—Ç–∞."
        await update.message.reply_text(reply)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å. –ü—Ä–æ–≤–µ—Ä—å —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.run_polling()
