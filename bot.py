
import logging
import os
import openai
import tempfile
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
# –ü–∞–º—è—Ç—å –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (–ø—Ä–∏–º–∏—Ç–∏–≤–Ω–∞—è, –º–æ–∂–Ω–æ –ø–æ–∑–∂–µ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ Redis –∏–ª–∏ —Ñ–∞–π–ª)
context_history = []
MAX_TURNS = 4  # —Å–∫–æ–ª—å–∫–æ —Ö–æ–¥–æ–≤ –ø–æ–º–Ω–∏—Ç—å (user + assistant)


load_dotenv()
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –ø–æ–º–æ—â–Ω–∏–∫ –∏ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä –ø–æ –∂–∏–∑–Ω–∏ –≤ —Ä–µ–π—Å–µ."

def load_relevant_knowledge(user_input: str) -> str:
    keywords_map = {
        "–æ—Ç–¥—ã—Ö": "rezhim_truda.md",
        "–ø–∞—É–∑": "rezhim_truda.md",
        "—Å–º–µ–Ω": "rezhim_truda.md",
        "—Ç–∞—Ö–æ–≥—Ä–∞—Ñ": "tahograf.md",
        "–∫–∞—Ä—Ç–∞": "tahograf.md",
        "ECTP": "ectp.md",
        "–ø–æ–µ–∑–¥": "ferry_routes.md",
        "–ø–∞—Ä–æ–º": "ferry_routes.md",
        "—Ü–º—Ä": "cmr.md",
        "–¥–æ–∫—É–º–µ–Ω—Ç": "cmr.md",
        "–∫–∞—Ç—è—â–µ–µ—Å—è —à–æ—Å—Å–µ": "katyaschee_shosse.md",
        "–∂–µ–ª–µ–∑–Ω": "katyaschee_shosse.md"
    }

    selected_files = set()
    lowered = user_input.lower()
    for keyword, filename in keywords_map.items():
        if keyword in lowered:
            selected_files.add(filename)

    texts = []
    for filename in sorted(selected_files):
        path = os.path.join("knowledge", filename)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    texts.append(
    f"üìò {filename}:\n"
    f"{content}\n"
)

    return "\n".join(texts) or ""

async def ask_gpt(messages):
    try:
        return openai.ChatCompletion.create(model="gpt-4o", messages=messages)
    except Exception as e:
        logging.warning(f"GPT-4o –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, fallback: {e}")
        try:
            return openai.ChatCompletion.create(model="gpt-3.5-turbo-1106", messages=messages)
        except Exception as e2:
            logging.error(f"GPT-3.5 —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
            return None

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –¥—Ä—É–≥ –∏ –Ω–∞–ø–∞—Ä–Ω–∏–∫. –ü–∏—à–∏ ‚Äî –ø–æ–º–æ–≥—É.")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    if not user_input:
        await update.message.reply_text("–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
context_history.append({"role": "user", "content": user_input})

# –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏—Å—Ç–æ—Ä–∏–µ–π
messages = [{"role": "system", "content": SYSTEM_PROMPT}]
kb_snippet = load_relevant_knowledge(user_input)
if kb_snippet:
    messages.append({"role": "system", "content": "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + kb_snippet})

# –í—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ä–µ–ø–ª–∏–∫–∏ –∏–∑ –ø–∞–º—è—Ç–∏
messages += context_history[-MAX_TURNS:]

# GPT –æ—Ç–≤–µ—á–∞–µ—Ç
response = await ask_gpt(messages)

# –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –≤ –ø–∞–º—è—Ç—å
if response:
    assistant_reply = response.choices[0].message.content.strip()
    context_history.append({"role": "assistant", "content": assistant_reply})
     await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ –º–æ–∂–µ—Ç –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()
