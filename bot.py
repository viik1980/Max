import logging
import os
import openai
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv

# –ü–∞–º—è—Ç—å –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ (–ø—Ä–∏–º–∏—Ç–∏–≤–Ω–∞—è, –º–æ–∂–Ω–æ –ø–æ–∑–∂–µ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ Redis –∏–ª–∏ —Ñ–∞–π–ª)
context_history = []
MAX_TURNS = 4  # —Å–∫–æ–ª—å–∫–æ —Ö–æ–¥–æ–≤ –ø–æ–º–Ω–∏—Ç—å (user + assistant)

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
openai.api_key = OPENAI_API_KEY

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –ø–æ–º–æ—â–Ω–∏–∫ –∏ –Ω–∞–≤–∏–≥–∞—Ç–æ—Ä –ø–æ –∂–∏–∑–Ω–∏ –≤ —Ä–µ–π—Å–µ."

# –ó–∞–≥—Ä—É–∑–∫–∞ –∑–Ω–∞–Ω–∏–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
def load_relevant_knowledge(user_input: str) -> str:
    keywords_map = {
        "–æ—Ç–¥—ã—Ö": "Rezim_RTO.md",
        "–ø–∞—É–∑": "Rezim_RTO.md",
        "—Å–º–µ–Ω": "Rezim_RTO.md",
        "—Ç–∞—Ö–æ–≥—Ä–∞—Ñ": "4_tahograf_i_karty.md",
        "–∫–∞—Ä—Ç–∞": "4_tahograf_i_karty.md",
        "–ø–æ–µ–∑–¥": "ferry_routes.md",
        "–ø–∞—Ä–æ–º": "ferry_routes.md",
        "—Ü–º—Ä": "CMR.md",
        "–¥–æ–∫—É–º–µ–Ω—Ç": "CMR.md",
        "–∫–æ–º—Ñ–æ—Ä—Ç": "11_komfort_i_byt.md",
        "–ø–∏—Ç–∞–Ω–∏–µ": "12_pitanie_i_energiya.md"
    }

    selected_files = set()
    lowered = user_input.lower()
    for keyword, filename in keywords_map.items():
        if keyword in lowered:
            selected_files.add(filename)

    texts = []
    for filename in sorted(selected_files):
        path = os.path.join("knowledge", filename)
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                content = f.read().strip()
                if content:
                    texts.append(f"üìò {filename}:\n{content}\n")

    return "\n".join(texts) or ""

# GPT-–∑–∞–ø—Ä–æ—Å
async def ask_gpt(messages):
    try:
        return openai.ChatCompletion.create(model="gpt-4o", messages=messages)
    except Exception as e:
        logging.warning(f"GPT-4o –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, fallback: {e}")
        try:
            return openai.ChatCompletion.create(model="gpt-3.5-turbo-1106", messages=messages)
        except Exception as e2:
            logging.error(f"GPT-3.5 —Ç–æ–∂–µ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e2}")
            return None

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä, –¥—Ä—É–≥ –∏ –Ω–∞–ø–∞—Ä–Ω–∏–∫. –ü–∏—à–∏ ‚Äî –ø–æ–º–æ–≥—É.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    if not user_input:
        await update.message.reply_text("–ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é
    context_history.append({"role": "user", "content": user_input})

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è GPT
    messages = [{"role": "system", "content": SYSTEM_PROMPT}]
    kb_snippet = load_relevant_knowledge(user_input)
    if kb_snippet:
        messages.append({"role": "system", "content": "üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + kb_snippet})

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Ö–æ–¥—ã
    messages += context_history[-MAX_TURNS:]

    # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç GPT
    response = await ask_gpt(messages)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
    if response:
        assistant_reply = response.choices[0].message.content.strip()
        context_history.append({"role": "assistant", "content": assistant_reply})
        await update.message.reply_text(assistant_reply)
    else:
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ GPT. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()
