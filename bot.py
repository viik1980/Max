import logging
import os
import openai
import tempfile
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise ValueError("–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY.")

openai.api_key = OPENAI_API_KEY

# –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç (–∏–∑ —Ñ–∞–π–ª–∞ prompt.txt –∏–ª–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –û–ø—ã—Ç–Ω—ã–π –¥–∏—Å–ø–µ—Ç—á–µ—Ä. –û—Ç–≤–µ—á–∞–π –ø–æ-–¥—Ä—É–∂–µ—Å–∫–∏, —Å –∑–∞–±–æ—Ç–æ–π, –ø–æ –¥–µ–ª—É."

# –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ –ø–∞–ø–∫–∏ knowledge
def load_all_knowledge():
    knowledge_dir = "knowledge"
    texts = []
    if not os.path.exists(knowledge_dir):
        logging.warning(f"–ü–∞–ø–∫–∞ —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π '{knowledge_dir}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return ""
    files = os.listdir(knowledge_dir)
    logging.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –≤ knowledge: {files}")
    for filename in sorted(files):
        # –î–ª—è –æ—Ç–ª–∞–¥–∫–∏ —É–±–∏—Ä–∞–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—é
        path = os.path.join(knowledge_dir, filename)
        if os.path.isfile(path):
            try:
                with open(path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if content:
                        texts.append(f"=== {filename} ===\n{content}\n")
                    else:
                        logging.warning(f"–§–∞–π–ª {filename} –ø—É—Å—Ç–æ–π.")
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π {filename}: {e}")
        else:
            logging.info(f"{filename} –Ω–µ —Ñ–∞–π–ª, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
    return "\n".join(texts)


KNOWLEDGE_BASE = load_all_knowledge()
logging.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–∞ –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π, —Å–∏–º–≤–æ–ª–æ–≤: {len(KNOWLEDGE_BASE)}")

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    logging.info("[LOG] /start –ø–æ–ª—É—á–µ–Ω–∞")
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä –∏ –¥—Ä—É–≥. –ü–∏—à–∏ –∏–ª–∏ –≥–æ–≤–æ—Ä–∏ ‚Äî —Ä–∞–∑–±–µ—Ä—ë–º—Å—è!")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    logging.info(f"[LOG] –ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_input}")

    if not user_input:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏, —á–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    try:
        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
        ]
        if KNOWLEDGE_BASE:
            messages.append({"role": "system", "content": "üìö –í–æ—Ç –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–º–æ—â–∏:\n" + KNOWLEDGE_BASE})
        messages.append({"role": "user", "content": user_input})

        response = openai.ChatCompletion.create(
            model="GPT-4.1-–º–∏–Ω–∏",
            messages=messages
        )
        logging.info(f"[LOG] GPT —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç: {response}")
        reply = response.choices[0].message.content if response.choices else "GPT –Ω–µ –¥–∞–ª –æ—Ç–≤–µ—Ç–∞."
        await update.message.reply_text(reply)

    except Exception as e:
        logging.error(f"[ERROR] GPT –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ –º–æ–∂–µ—Ç —Å–≤—è–∑–∞—Ç—å—Å—è —Å GPT. –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".oga") as f:
            await file.download_to_drive(f.name)
            audio_path = f.name

        with open(audio_path, "rb") as audio_file:
            transcript = openai.Audio.transcribe("whisper-1", audio_file)
            user_text = transcript.get("text", "")

        if not user_text:
            await update.message.reply_text("–ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π —Å–∫–∞–∑–∞—Ç—å —Å–Ω–æ–≤–∞.")
            return

        await update.message.reply_text(f"–¢—ã —Å–∫–∞–∑–∞–ª: {user_text}")

        messages = [
            {"role": "system", "content": SYSTEM_PROMPT},
        ]
        if KNOWLEDGE_BASE:
            messages.append({"role": "system", "content": "üìö –í–æ—Ç –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –¥–ª—è –ø–æ–º–æ—â–∏:\n" + KNOWLEDGE_BASE})
        messages.append({"role": "user", "content": user_text})

        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=messages
        )
        logging.info(f"[LOG] GPT –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç: {response}")
        reply = response.choices[0].message.content if response.choices else "GPT –Ω–µ –¥–∞–ª –æ—Ç–≤–µ—Ç–∞."
        await update.message.reply_text(reply)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å. –ü—Ä–æ–≤–µ—Ä—å —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.run_polling()
