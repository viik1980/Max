import logging
import os
import tempfile
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
from openai import AsyncOpenAI  # –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç OpenAI

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise ValueError("–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è!")

# –°–æ–∑–¥–∞—ë–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –∏–∑ –ø–∞–ø–∫–∏ knowledge
def load_knowledge(filename):
    try:
        with open(f"knowledge/{filename}", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return ""

def load_all_knowledge():
    knowledge_base = ""
    knowledge_dir = "knowledge"
    if os.path.exists(knowledge_dir):
        for filename in os.listdir(knowledge_dir):
            if filename.endswith(".txt"):
                knowledge_base += f"\n--- {filename} ---\n"
                knowledge_base += load_knowledge(filename)
                knowledge_base += "\n"
    return knowledge_base.strip()

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º—Ç–∞
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        SYSTEM_PROMPT = f.read()
except FileNotFoundError:
    SYSTEM_PROMPT = "–¢—ã ‚Äî –ú–∞–∫—Å. –û–ø—ã—Ç–Ω—ã–π –¥–∏—Å–ø–µ—Ç—á–µ—Ä. –û—Ç–≤–µ—á–∞–π –ø–æ-–¥—Ä—É–∂–µ—Å–∫–∏, —Å –∑–∞–±–æ—Ç–æ–π, –ø–æ –¥–µ–ª—É –∏ —Å —É–º–µ—Å—Ç–Ω—ã–º —é–º–æ—Ä–æ–º."

# –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
KNOWLEDGE_BASE = load_all_knowledge()

# –ö–æ–º–∞–Ω–¥–∞ /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ó–¥–æ—Ä–æ–≤–∞, —è ‚Äî –ú–∞–∫—Å. –î–∏—Å–ø–µ—Ç—á–µ—Ä –∏ –¥—Ä—É–≥. –ü–∏—à–∏ –∏–ª–∏ –≥–æ–≤–æ—Ä–∏ ‚Äî —Ä–∞–∑–±–µ—Ä—ë–º—Å—è!")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text.strip()
    logging.info(f"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: {user_input}")

    if not user_input:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏, —á–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        return

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT + "\n\nüìö –í–æ—Ç –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + KNOWLEDGE_BASE},
        {"role": "user", "content": user_input},
    ]

    try:
        response = await client.chat.completions.acreate(
            model="gpt-4o",
            messages=messages
        )
        reply = response.choices[0].message.content
        await update.message.reply_text(reply)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ OpenAI: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ –º–æ–∂–µ—Ç —Å–≤—è–∑–∞—Ç—å—Å—è —Å GPT. –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞.")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        file = await update.message.voice.get_file()
        with tempfile.NamedTemporaryFile(delete=False, suffix=".oga") as f:
            await file.download_to_drive(f.name)
            audio_path = f.name

        with open(audio_path, "rb") as audio_file:
            transcript = await client.audio.transcriptions.acreate(
                model="whisper-1",
                file=audio_file
            )
            user_text = transcript.get("text", "")

        if not user_text:
            await update.message.reply_text("–ù–µ —Å–º–æ–≥ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π —Å–∫–∞–∑–∞—Ç—å —Å–Ω–æ–≤–∞.")
            return

        await update.message.reply_text(f"–¢—ã —Å–∫–∞–∑–∞–ª: {user_text}")

        messages = [
            {"role": "system", "content": SYSTEM_PROMPT + "\n\nüìö –í–æ—Ç –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π:\n" + KNOWLEDGE_BASE},
            {"role": "user", "content": user_text},
        ]

        response = await client.chat.completions.acreate(
            model="gpt-4o",
            messages=messages
        )
        reply = response.choices[0].message.content
        await update.message.reply_text(reply)
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text("‚ö†Ô∏è –ú–∞–∫—Å –Ω–µ —Å–º–æ–≥ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≥–æ–ª–æ—Å. –ü—Ä–æ–≤–µ—Ä—å —Ñ–æ—Ä–º–∞—Ç –∏–ª–∏ –ø–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.add_handler(MessageHandler(filters.VOICE, handle_voice))
    app.run_polling()
